{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f9d493-34e7-440d-9264-479410833e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencsis \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f69384-1a74-4d30-beed-20c937042c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Preposeccing \n",
    "\n",
    "class SentimentPreprocessor:\n",
    "    def _init_(self):\n",
    "        #initialize request components \n",
    "        self.tokenizer = ToktokTokenizer()\n",
    "        self.nlp = spacy.laod('en_core_web_sm',disable=['ner'])\n",
    "        self.stopword_list = nltk.corpus.stopwords.words('english')\n",
    "        #removing not and no from the stopwords as they are important for sentiment \n",
    "        self.stopword_list.remove('no')\n",
    "        selft.stopword_list.remove('not')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a82cde4-52c9-4e23-a11b-3db75885c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(self,text):\n",
    "    #complete preprocessing of the text input prediction\n",
    "    text = str(text)\n",
    "    text = self.remove_html(text)\n",
    "    text = self.remove_URL(text)\n",
    "    text = text.encode('ascii','ignore').decode('ascii')\n",
    "    text = self.remove_punctuations(text)\n",
    "    text = self.remove_special_characters(text)\n",
    "    text = self.remove_numbers(text)\n",
    "    text = self.remove_alphanumeric(text)\n",
    "    text = self.custom_remove_stopwords(text)\n",
    "    text = self.lemmatize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ceac6d-0241-47a3-b4a9-e47c87beb63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(self,text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71eeba8a-4b64-40c4-bb6e-8fcf88265f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(self,text):\n",
    "    url = re.compile(r'https?://\\s+|www\\.\\s+')\n",
    "    return url.sub(r'',text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8437afc-d541-47f5-9d00-f613c532550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(self,text):\n",
    "    import string\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af564ea2-8986-4ba6-b451-03a452641f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(self,text):\n",
    "    return re.sub('[^a-zA-z0-9\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82570e68-30d5-4835-b5d6-3287d8eefe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(self, text):\n",
    "        return ''.join([i for i in text if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a1cd5fe-8606-425b-be75-324a96ac853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(self, word):\n",
    "        rx = re.compile(r'\\D*\\d')\n",
    "        if rx.match(word):\n",
    "            return ''\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303a524a-45a6-4202-9c8b-7bd6c76963c6",
   "metadata": {},
   "outputs": [],
   "source": [
    " def remove_alphanumeric(self, strings):\n",
    "        nstrings = [\" \".join(filter(None, (self.cleanse(word) for word in string.split())))\n",
    "                   for string in strings.split()]\n",
    "        return ' '.join(nstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed43869-bb48-4608-90fd-4a08487a7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def custom_remove_stopwords(self, text, is_lower_case=False):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        tokens = [token.strip() for token in tokens]\n",
    "        if is_lower_case:\n",
    "            filtered_tokens = [token for token in tokens if token not in self.stopword_list]\n",
    "        else:\n",
    "            filtered_tokens = [token for token in tokens if token.lower() not in self.stopword_list]\n",
    "        return ' '.join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f0050-f4cd-43b1-bf57-8a07202acb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(self, text):\n",
    "        text = self.nlp(text)\n",
    "        text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2800a49-6714-4556-afae-d76eaf3242a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(self, text):\n",
    "        \"\"\"Get sentiment scores for processed text\"\"\"\n",
    "        sentiment = TextBlob(text).sentiment\n",
    "        return {\n",
    "            'polarity': sentiment.polarity,\n",
    "            'subjectivity': sentiment.subjectivity,\n",
    "            'sentiment': 'Positive' if sentiment.polarity >= 0.3 else 'Negative'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bce17e5-dcfc-44fe-8a2a-72eb197bb3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessor\n",
    "preprocessor = SentimentPreprocessor()\n",
    "with open('sentiment_preproces.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619d188-65c2-4f1f-aa9f-cc0fefc79330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
